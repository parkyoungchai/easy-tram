import streamlit as st
import google.generativeai as genai
from PIL import Image
from gtts import gTTS
import speech_recognition as sr
import os
import time
import io  # ğŸ‘ˆ ëª¨ë°”ì¼ ì†Œë¦¬ ì—ëŸ¬ í•´ê²°ì„ ìœ„í•œ í•µì‹¬ ë„êµ¬!

# ğŸ‘‡ 6ë²ˆì§¸ ì¤„: Gemini í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”!
GEMINI_API_KEY = "AIzaSyB-d0aIFMTsQQAsf0_Dm1qupfKOvRsKvo0"

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('models/gemini-flash-latest')

st.set_page_config(page_title="ëŒ€ì „ Easy-Tram", page_icon="ğŸšƒ", layout="centered")
st.title("ğŸšƒ ëŒ€ì „ Easy-Tram")
st.subheader("ì–´ë¥´ì‹ , ê¶ê¸ˆí•œ ê²ƒì„ ì°ì–´ë³´ì„¸ìš”")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None

# ğŸ”Š AIê°€ ë§í•˜ê²Œ í•˜ëŠ” í•¨ìˆ˜ (ëª¨ë°”ì¼ í˜¸í™˜ì„± UP!)
def speak(text):
    try:
        tts = gTTS(text=text, lang='ko')
        # íŒŒì¼ì„ ë§Œë“¤ì§€ ì•Šê³  ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ ì¬ìƒ (ì—ëŸ¬ ê°ì†Œ)
        mp3_fp = io.BytesIO()
        tts.write_to_fp(mp3_fp)
        st.audio(mp3_fp, format='audio/mp3', start_time=0)
    except Exception:
        st.warning("ğŸ”Š (ì£„ì†¡í•´ìœ . ì§€ê¸ˆ í•¸ë“œí°ì—ì„œëŠ” ì†Œë¦¬ê°€ ì•ˆ ë‚  ìˆ˜ë„ ìˆì–´ìœ .)")

def listen_to_user():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        status = st.toast("ğŸ‘‚ ë“£ê³  ìˆì–´ìœ ... ë§ì”€í•˜ì…”ìœ !")
        try:
            audio = r.listen(source, timeout=5, phrase_time_limit=10)
            text = r.recognize_google(audio, language='ko-KR')
            return text
        except Exception:
            return None

def show_minwon_button():
    with st.expander("ğŸ“ ê·¸ë˜ë„ ê¶ê¸ˆí•œ ê²Œ ë‚¨ìœ¼ì…¨ë‚˜ìš”? (ì—¬ê¸°ë¥¼ ëˆŒëŸ¬ë³´ì„¸ìš”)"):
        st.write("AI ë¹„ì„œê°€ ë¶€ì¡±í•´ì„œ ì£„ì†¡í•´ìš”. ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ëŒ€ì „ì‹œ ìƒë‹´ì›(120)ì—ê²Œ ë°”ë¡œ ì „í™” ì—°ê²°ë©ë‹ˆë‹¤.")
        st.link_button("ğŸ‘©â€ğŸ’¼ ìƒë‹´ì›ì—ê²Œ ì „í™”í•˜ê¸° (120)", "tel:120", use_container_width=True)

uploaded_file = st.file_uploader("ì‚¬ì§„ ì°ê¸°", type=["jpg", "png", "jpeg"])

if uploaded_file:
    if st.session_state.uploaded_image != uploaded_file:
        st.session_state.chat_history = []
        st.session_state.uploaded_image = uploaded_file

    image = Image.open(uploaded_file)
    st.image(image, caption='ì°ì€ ì‚¬ì§„')

    # --- [1ì°¨ ë¶„ì„] ---
    if not st.session_state.chat_history:
        with st.spinner('AI ë¹„ì„œê°€ ì‚¬ì§„ì„ ë³´ê³  ìˆìŠµë‹ˆë‹¤...'):
            try:
                prompt = """
                ë‹¹ì‹ ì€ ì–´ë¥´ì‹ ì„ ìœ„í•œ 'êµí†µ ì•ˆë‚´ ë¹„ì„œ'ì…ë‹ˆë‹¤.
                ì‚¬ì§„ì„ ë³´ê³  í•µì‹¬ ë‚´ìš©ì„ ì‰¬ìš´ ìš°ë¦¬ë§ ì¡´ëŒ“ë§ë¡œ 3~5ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                "ì–´ë¥´ì‹ ," í•˜ê³  ë”°ëœ»í•˜ê²Œ ë¶€ë¥´ë©° ì‹œì‘í•˜ì„¸ìš”.
                (ì ˆëŒ€ë¡œ ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì§€ ë§ˆì„¸ìš”.)
                """
                response = model.generate_content([prompt, image])
                st.session_state.chat_history.append({"role": "ai", "text": response.text})
                st.rerun()
            except Exception as e:
                st.error(f"ì˜¤ë¥˜: {e}")

    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for i, message in enumerate(st.session_state.chat_history):
        if message["role"] == "ai":
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.write(message['text'])
                # ë§ˆì§€ë§‰ ë‹µë³€ì—ë§Œ ì†Œë¦¬ ì¬ìƒê¸°ì™€ ë¯¼ì› ë²„íŠ¼ ë‹¬ê¸°
                if i == len(st.session_state.chat_history) - 1:
                     speak(message['text'])
                     show_minwon_button()
        else:
             with st.chat_message("user", avatar="ğŸ‘¤"):
                st.write(message['text'])

    # --- [ì¶”ê°€ ì§ˆë¬¸ ê¸°ëŠ¥] ---
    st.write("---")
    col1, col2 = st.columns([4, 1])
    with col1:
        user_input = st.text_input("ê¶ê¸ˆí•œ ì ì„ ì ê±°ë‚˜ ë§ˆì´í¬ë¥¼ ëˆ„ë¥´ì„¸ìš”", key="user_input_box")
    with col2:
        if st.button("ğŸ¤ ë§í•˜ê¸°"):
            voice_text = listen_to_user()
            if voice_text:
                st.session_state.chat_history.append({"role": "user", "text": voice_text})
                st.rerun()

    if user_input and st.button("ì§ˆë¬¸ ë³´ë‚´ê¸°"):
         st.session_state.chat_history.append({"role": "user", "text": user_input})
         st.rerun()

    if st.session_state.chat_history and st.session_state.chat_history[-1]["role"] == "user":
        with st.spinner('ë‹µë³€ì„ ìƒê° ì¤‘ì…ë‹ˆë‹¤...'):
            try:
                last_question = st.session_state.chat_history[-1]["text"]
                follow_up_prompt = f"ì–´ë¥´ì‹  ì§ˆë¬¸: '{last_question}'\nì‰½ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. (í•œêµ­ì–´ë§Œ ì‚¬ìš©)"
                response = model.generate_content([follow_up_prompt, image])
                st.session_state.chat_history.append({"role": "ai", "text": response.text})
                st.rerun()
            except Exception as e:
                st.error(f"ì˜¤ë¥˜: {e}")