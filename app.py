import streamlit as st
import google.generativeai as genai
from PIL import Image
from gtts import gTTS  # TTS í•¨ìˆ˜ ë‚´ì—ì„œë§Œ ì‚¬ìš© (ì „ì—­ ë³€ìˆ˜ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
import os
import io

# --- [1. í•„ìˆ˜ ì„¤ì •] ---------------------------------------------------------
# ğŸ‘‡ 6ë²ˆì§¸ ì¤„: Gemini API í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”!
GEMINI_API_KEY = "AIzaSyB-d0aIFMTsQQAsf0_Dm1qupfKOvRsKvo0"

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('models/gemini-flash-latest')
# ---------------------------------------------------------------------------

# === ì„¸ì…˜ ìƒíƒœ ë° ë„ìš°ë¯¸ í•¨ìˆ˜ ===
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ë©”ì¸ ë¡œì§ë³´ë‹¤ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "uploaded_image_bytes" not in st.session_state:
    st.session_state.uploaded_image_bytes = None
    
# ğŸ”Š AIê°€ ë§í•˜ê²Œ í•˜ëŠ” í•¨ìˆ˜ (ëª¨ë°”ì¼ í˜¸í™˜ì„± ìµœì í™”)
def speak(text):
    try:
        tts = gTTS(text=text, lang='ko')
        mp3_fp = io.BytesIO()
        tts.write_to_fp(mp3_fp)
        st.audio(mp3_fp, format='audio/mp3', start_time=0)
    except Exception:
        st.warning("ğŸ”Š (ì†Œë¦¬ ì¬ìƒì´ ì›í™œí•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¬ìƒ ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”.)")

# ğŸ“ ë¯¼ì› ë²„íŠ¼ í•¨ìˆ˜
def show_minwon_button():
    with st.expander("ğŸ“ ê·¸ë˜ë„ ê¶ê¸ˆí•œ ê²Œ ë‚¨ìœ¼ì…¨ë‚˜ìš”?"):
        st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ëŒ€ì „ì‹œ ìƒë‹´ì›(120)ì—ê²Œ ë°”ë¡œ ì „í™” ì—°ê²°ë©ë‹ˆë‹¤.")
        st.link_button("ğŸ‘©â€ğŸ’¼ ìƒë‹´ì› ì „í™” ì—°ê²° (120)", "tel:120", use_container_width=True)

# === í™”ë©´(UI) êµ¬ì„± ===
st.set_page_config(page_title="ëŒ€ì „ Easy-Tram", page_icon="ğŸšƒ", layout="centered")
st.title("ğŸšƒ ëŒ€ì „ Easy-Tram")
st.subheader("ì–´ë¥´ì‹ , ê¶ê¸ˆí•œ ê²ƒì„ ì°ì–´ë³´ì„¸ìš”")

uploaded_file = st.file_uploader("ì‚¬ì§„ ì°ê¸°", type=["jpg", "png", "jpeg"])

# íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ë° ì´ë¯¸ì§€ ì €ì¥
if uploaded_file:
    # ğŸš¨ íŒŒì¼ì´ ìƒˆë¡œ ì—…ë¡œë“œë˜ë©´, ë°”ì´íŠ¸ í˜•íƒœë¡œ ì €ì¥í•˜ì—¬ ì´ë¯¸ì§€ ë³€ìˆ˜ ì—ëŸ¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    if uploaded_file.getvalue() != st.session_state.uploaded_image_bytes:
        st.session_state.chat_history = []
        st.session_state.uploaded_image_bytes = uploaded_file.getvalue()

    # ì €ì¥ëœ ë°”ì´íŠ¸ ë°ì´í„°ì—ì„œ PIL Image ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    image = Image.open(io.BytesIO(st.session_state.uploaded_image_bytes))
    st.image(image, caption='ì°ì€ ì‚¬ì§„', use_column_width=True)

    # --- [1ì°¨ ë¶„ì„] ---
    if not st.session_state.chat_history:
        with st.spinner('AI ë¹„ì„œê°€ ì‚¬ì§„ì„ ë³´ê³  ìˆìŠµë‹ˆë‹¤...'):
            try:
                prompt = """
                ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì˜ˆì˜ ë°”ë¥¸ 'êµí†µ ì•ˆë‚´ ë¹„ì„œ'ì…ë‹ˆë‹¤.
                ì‚¬ì§„ì„ ë³´ê³  í•µì‹¬ ë‚´ìš©ì„ ì‰¬ìš´ í‘œì¤€ì–´ ì¡´ëŒ“ë§ë¡œ 3~5ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                'ì–´ë¥´ì‹ ,' í•˜ê³  ë¶€ë¥´ë©° ì‹œì‘í•˜ê³ , (ì ˆëŒ€ë¡œ ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì§€ ë§ˆì„¸ìš”.)
                """
                
                response = model.generate_content([prompt, image])
                st.session_state.chat_history.append({"role": "ai", "text": response.text})
                st.rerun() # ìƒˆë¡œê³ ì¹¨í•´ì„œ ë‹µë³€ ë³´ì—¬ì£¼ê¸°

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for i, message in enumerate(st.session_state.chat_history):
        if message["role"] == "ai":
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.write(message['text'])
                if i == len(st.session_state.chat_history) - 1:
                     speak(message['text'])
                     show_minwon_button()
        else:
             with st.chat_message("user", avatar="ğŸ‘¤"):
                st.write(message['text'])

    # --- [ì¶”ê°€ ì§ˆë¬¸ ê¸°ëŠ¥] ---
    # *st.chat_inputì„ ì‚¬ìš©í•˜ë©´ Enter í‚¤ë¥¼ ëˆŒëŸ¬ë„ ì§ˆë¬¸ì´ ì „ì†¡ë©ë‹ˆë‹¤.*
    user_input = st.chat_input("ê¶ê¸ˆí•œ ì ì„ ì ê±°ë‚˜, í‚¤ë³´ë“œì˜ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§ì”€í•´ë³´ì„¸ìš”")

    if user_input:
        st.session_state.chat_history.append({"role": "user", "text": user_input})
        with st.spinner('ë‹µë³€ì„ ìƒê° ì¤‘ì…ë‹ˆë‹¤...'):
            try:
                # ì´ì „ ëŒ€í™”ì™€ í˜„ì¬ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±
                follow_up_prompt = f"ì–´ë¥´ì‹  ì§ˆë¬¸: '{user_input}'\nì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•˜ì—¬ ì‰½ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. (í•œêµ­ì–´ë§Œ ì‚¬ìš©)"
                
                # ì´ë¯¸ì§€ ê°ì²´ë¥¼ ë‹¤ì‹œ ìƒì„±í•´ì•¼ í•¨ (Streamlitì˜ íŠ¹ì„±)
                current_image = Image.open(io.BytesIO(st.session_state.uploaded_image_bytes))
                
                response = model.generate_content([follow_up_prompt, current_image])
                st.session_state.chat_history.append({"role": "ai", "text": response.text})
                st.rerun()
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")